# ğŸ¤– AI Document Q&A Chatbot with RAG

A **Generative AIâ€“powered Document Question & Answering Chatbot** built using **Retrieval-Augmented Generation (RAG)**.  
The system enables accurate, low-latency question answering over private documents by combining vector search with large language models.

---

## ğŸš€ Key Highlights

- ğŸ“„ Built a **GenAI chatbot** using Retrieval-Augmented Generation  
- ğŸ¯ Achieved **95%+ accuracy** on document-based queries  
- âš¡ Sub-2-second response time in production  
- â˜ï¸ Fully deployed on **AWS** with containerized infrastructure  

---

## ğŸ§  System Architecture

### Retrieval-Augmented Generation (RAG) Pipeline

1. **Document Ingestion**
   - Documents are chunked and embedded using **Amazon Titan Embeddings**

2. **Vector Storage**
   - Embeddings stored in **Amazon OpenSearch (Vector DB)**  
   - Managed through **AWS Bedrock Knowledge Bases**

3. **Query Flow**
   - User query â†’ embedded â†’ vector similarity search  
   - Relevant document chunks retrieved

4. **Answer Generation**
   - Retrieved context passed to **LLM (via AWS Bedrock / OpenAI)**  
   - Final grounded response generated

---

## ğŸ› ï¸ Tech Stack

- **Programming Language:** Python  
- **LLMs:** OpenAI / AWS Bedrock  
- **Embeddings:** Amazon Titan  
- **Vector Database:** Amazon OpenSearch  
- **RAG Framework:** LlamaIndex  
- **Deployment:** Docker, AWS EC2  

---

## âš™ï¸ Deployment

- Dockerized application for portability and scalability  
- Deployed on **AWS EC2**  
- Optimized for:
  - Low latency
  - High retrieval accuracy
  - Production stability

---

## ğŸ“Š Performance

| Metric | Result |
|------|-------|
| Document Q&A Accuracy | **95%+** |
| Average Response Time | **< 2 seconds** |
| Retrieval Type | Hybrid Vector Search |

---

## ğŸ“Œ Use Cases

- Enterprise document Q&A  
- Internal knowledge base assistants  
- Policy and compliance document search  
- Research paper and PDF analysis  

---

## ğŸ”’ Why RAG?

- Prevents hallucinations  
- Grounds answers in real documents  
- Keeps proprietary data private  
- Easily updatable without retraining models  

---


#GenAI #RAG` `#LLM` `#AWS` `#Bedrock` `#OpenSearch` `#LlamaIndex` `#Docker` `#Python`

---
